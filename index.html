<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Auto Driving DAO</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Auto Driving DAO: Driving the Future of Mobility</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="FIRST AUTHOR PERSONAL LINK" target="_blank">First Author</a><sup>*</sup>,</span>
                <span class="author-block">
                  <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Second Author</a><sup>*</sup>,</span>
                  <span class="author-block">
                    <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Third Author</a>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">Institution Name<br>Conferance name and year</span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/Auto-Driving-DAO/OAD" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        <!-- Your video here -->
        <source src="static/videos/banner_video.mp4"
        type="video/mp4">
      </video>
      <h3 class="subtitle has-text-centered"> What is AutoDriving DAO?
      </h3>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Autonomous driving technologies are revolutionizing transportation and mobility, with the groundbreaking development of data-driven end-to-end autonomous driving models at its core, offering unprecedented intelligence, efficiency and reliability. Despite this potential, current models often fall short due to reliance on proprietary and rule-based frameworks.
          </p>
          <p>
          <b>Auto Driving DAO</b> aims to unlock the full potential of autonomous driving through open-source collaboration, inviting the global community to join forces in creating innovative models. This cross-continental initiative is facilitated by the <a href="https://mirror.xyz/orablog.eth/xYMD27tN23ppbKCluB9faytF_W6M1hKXTuKcfkm3D50">Initial Model Offering</a> (IMO), which tokenizes AI models on the blockchain, enabling collaborative contributions, efficient resource coordination, and equitable compensation.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Introduction -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Introduction</h2>
        
        <div class="content has-text-justified">
          <p>
            The autonomous driving industry is undergoing a significant transformation, shifting from traditional rule-based systems to data-driven, end-to-end models. Here’s how these two approaches differ:
          </p>
          <ul>
            <li><strong>Rule-Based Systems</strong>: These rely on predefined rules and algorithms to navigate driving scenarios. While effective in controlled environments, they often struggle with the unpredictability of real-world situations, requiring extensive management of thousands of corner cases (e.g., dealing with a plastic bag on the road).</li>
            <li><strong>End-to-End Systems</strong>: In contrast, end-to-end models leverage AI to learn directly from vast amounts of data. These models interpret sensor data and make driving decisions in real time, providing a flexible and robust solution that adapts to complex driving environments.</li>
          </ul>
          <p>
            Currently, industry leaders exploring end-to-end models, such as Tesla, Waymo, Cruise, Baidu, Huawei, SenseTime, and Xpeng, operate as closed-source proprietary companies. Meanwhile, open-source implementations like OpenPilot face limitations in feature support, resource allocation, and community incentives. The industry is in dire need of a true open-source end-to-end autonomous driving model. To meet this challenge, Auto Driving DAO proposes the OpenAutoDriving (OAD) framework—an end-to-end autonomous driving system designed for flexibility and robustness, and an open-source framework where contributors can collaborate and be fairly rewarded for their contributions.
          </p>
          <b>If Tesla represents Apple with its closed-source models, then Auto Driving DAO embodies Android, laying the groundwork for open-source foundational models accessible to all vehicles.</b>
        
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Why Open Source? -->
<section class="section">
  <div class="container is-max-desktop">
    <!--/ Results. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">AutoDriving DAO Initiative</h2>
        
        <div class="content has-text-justified">
          <p>
            Auto Driving DAO is a platform committed to developing fully open-source transformer-native models for autonomous driving. By embracing an open-source approach, we invite the global community to contribute to and refine these models and their underlying computing resources, ensuring transparency, verifiability, and ownership.
          </p>
          <h3>Why Open Source?</h3>
          <ol>
            <li>
                <strong>Efficiency through Shared Investment</strong>:
                <p>An open platform minimizes unnecessary duplication of efforts and investments among original equipment manufacturers (OEMs). By pooling resources, OEMs can focus on innovation, leading to more efficient use of time and capital, while also reducing computing power needs and limiting environmental impact.</p>
            </li>
            <li>
                <strong>Customizable and Flexible Solutions</strong>:
                <p>Unlike proprietary systems, which often offer limited customization, an open-source approach empowers OEMs to tailor solutions to their specific needs. This flexibility enables manufacturers to optimize technology for their vehicles, creating unique competitive advantages in the market.</p>
            </li>
            <li>
                <strong>Accelerated Development and Deployment</strong>:
                <p>Open-source platforms expedite the development and deployment of autonomous driving technologies. By reducing the effort required for OEMs to bring products to market, this approach allows for quicker adaptation to evolving market demands and technological advancements.</p>
            </li>
            <li>
                <strong>Access to Wider Data Sources</strong>:
                <p>An open-source approach harnesses a broader range of data sources, resulting in more comprehensive and accurate training data for AI models. This diversity enhances the model's ability to navigate real-world driving conditions effectively.</p>
            </li>
            <li>
                <strong>Collaborative Innovation</strong>:
                <p>Open-source fosters a culture of collaborative innovation, harnessing the collective intelligence and creativity of a global community to drive continuous improvement. Such collaboration can lead to breakthroughs unattainable within closed systems.</p>
            </li>
            <li>
                <strong>Improved Safety and Reliability</strong>:
                <p>Open-source models enhance safety and reliability by leveraging insights from diverse developers and experts. The transparency of the code allows for thorough vetting and testing, minimizing unforeseen issues and boosting overall trust in the technology.</p>
            </li>
          </ol>
        
        </div>
      </div>
    </div>    
  </div>
</section>

<!-- Our Vision (DAO & IMO) -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Our Vision</h2>
        <div class="content has-text-justified">
          <p>
            Despite the growing advancements in autonomous driving, the industry still lacks a fully deployable, mature open-source solution. This gap exists due to the immense investment required, the lengthy training and testing cycles, and the reliance on proprietary data—all of which have made the dream of an open-source self-driving system seem unattainable.
          </p>
          <p>
            However, AutoDriving DAO is changing that. By leveraging the Initial Model Offering (IMO), we are enabling the global community to contribute to the development of autonomous driving models while being fairly rewarded. The IMO tokenizes AI models on the blockchain, creating a decentralized framework where resources, expertise, and contributions can be effectively coordinated and compensated.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Core Initiator -->
<section class="section">
  <div class="container is-max-desktop">
    <!--/ Results. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">AutoDriving DAO Community</h2>
        <div class="content has-text-justified">
          <p>The AutoDriving DAO is backed by a collaboration of pioneers from academia, industry, and blockchain innovation. Together, they bring the experience, knowledge, and infrastructure needed to make open-source autonomous driving a reality:</p>

          <ul>
              <li><strong>Academic Leaders</strong>: Researchers from prestigious institutions such as Stanford University bring cutting-edge expertise, spearheading the research and development of the OpenAutoDriving (OAD) model.</li>
              <li><strong>Industry Partners</strong>: We are partnering with global industry leaders in car manufacturing, who provide invaluable practical experience and data. Their expertise and resources are essential for developing and deploying a fully functional system.
              <li><strong>Blockchain Innovators</strong>: ORA Protocol provides the blockchain infrastructure necessary for decentralized governance, offering trustless, verifiable AI solutions on-chain. Their experience with the Initial Model Offering (IMO) and projects like OpenLM RevShare Token (OLM) will be crucial in managing contributions and rewarding the community.</li>
          </ul>

          <p>By bringing together these diverse leaders, AutoDriving DAO prioritizes the development of open-source solutions for autonomous driving. We invite researchers, builders, and innovators from around the world to join our community and help shape the future of mobility.</p>

        </div>
      </div>
    </div>    
  </div>
</section>

<!-- Technical Paragraph 1 -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Technical Architecture</h2>
        <div class="content has-text-justified">
          <p>
            The proposed autonomous driving system is an end-to-end multimodal framework that leverages advanced transformer-based architectures to address the complexity of dynamic driving environments. The system is modular, scalable, and capable of handling diverse tasks ranging from perception and decision-making to reasoning and language alignment. More precisely, the system is structured into four key components:
          </p>
          <ul>
            <li>The AutoDriving Multimodal Perception System (OAD-VIT)</li>
            <li>The AutoDriving Visual Language Alignment System (OAD-QFormer)</li>
            <li>The AutoDriving Multi-task Driving System (OAD-MTDS)</li>
            <li>The AutoDriving Reasoning and Decision System (OAD-RDS)</li>
          </ul>
          <p>
            <img src="/static/images/mmvit.png" alt="Multimodal Vision Transformer">
          </p>
          <p>
            The OAD-VIT handles sensor fusion and spatial feature extraction through vision, LiDAR, and RiDAR inputs, while OAD-QFormer bridges visual and language modalities to enhance real-time scene understanding. OAD-MTDS enables task-specific predictions for object detection, lane detection, and other critical driving tasks using perception queries. Finally, the OAD-RDS integrates a large language model to facilitate high-level decision-making, path planning, and control generation based on 3D perception. Each module is interconnected through a query-based architecture, allowing efficient information exchange, while maintaining computational efficiency and scalability for diverse driving scenarios.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Technical Paragraph 2 -->
<section class="section hero is-small">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="content has-text-justified">
          <ul>
            <li>
              The <strong>Multimodal Perception System</strong> is the foundation, integrating high-resolution data from various sensors such as video, LiDAR, and Radar. This system ensures that the vehicle can accurately perceive its surroundings by converting complex multi-view inputs into sparse yet information-rich queries, allowing for efficient processing while maintaining critical spatial and semantic details.
            </li>
            <li>
              Building on this, the <strong>Visual-Language Alignment System</strong> enhances the vehicle's ability to not only perceive but also reason about its environment by aligning visual inputs with language-based reasoning. This step allows the system to understand scene context and make informed decisions without the need for extensive computational resources, facilitating real-time decision-making even in resource-constrained settings.
            </li>
            <li>
              To manage the multiple driving tasks—such as object detection, lane detection, and motion planning—the <strong>Multi-task Driving System</strong> is designed to handle various tasks simultaneously using the same transformer-based query architecture. This design allows the system to efficiently process multiple inputs and produce task-specific outputs, ensuring that the vehicle can navigate complex driving scenarios with minimal latency.
            </li>
            <li>
              Finally, the <strong>Reasoning and Decision System</strong> integrates cutting-edge large language models (LLMs) to process 3D environmental data and make high-level driving decisions. This system not only predicts actions based on current surroundings but also enables counterfactual reasoning and scene-based questioning, adding a layer of human interpretability to the vehicle’s decision-making process.
            </li>
          </ul>
          <p>
            <img src="/static/images/omnidrive.png" alt="AutoDriving Agent Diagram">
          </p>
          <p>
            Together, these four components form a cohesive architecture that balances the complexity of perception, language understanding, task execution, and reasoning, making OAD a powerful platform for autonomous driving.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- DAO Governance -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">DAO Governance</h2>
        <div class="content has-text-justified">
          <p>
            A <strong>Decentralized Autonomous Organization (DAO)</strong> is a governance model that allows decisions to be made collectively by the community rather than a centralized authority. Built on blockchain technology, a DAO operates through smart contracts that enforce rules and automate decision-making processes. Members of the DAO typically hold tokens, which give them voting power to propose and vote on changes, ensuring transparency, security, and shared control over the organization’s direction.
          </p>
          <h3>i. Core Principles</h3>
          <ul>
            <li>
              <strong>Open Source as the First Principle</strong>: OpenAutoDriving (OAD) models are fundamentally open-source, ensuring transparency, collaborative development, and accessibility. By making the project’s models and codebase openly available, all stakeholders—including researchers, developers, OEMs, and the broader community—are invited to access, contribute to, and enhance the system.
            </li>
            <li>
              <strong>DAO Governance</strong>: Governance of the OAD ecosystem will be conducted through a Decentralized Autonomous Organization (DAO), where decision-making processes are executed on-chain via smart contracts. Token holders are empowered to participate directly in governance, ensuring decentralized control, collective decision-making, and transparent oversight of the project's direction and resource allocation.
            </li>
            <li>
              <strong>Tokenization for Incentivization</strong>: The introduction of the OAD token serves a dual purpose within the governance and incentivization framework. It facilitates participation in decision-making processes while also providing compensation for contributors (developers, researchers, data providers, computing resource providers, etc.). This token-based system aligns stakeholder incentives with the project’s long-term success, promoting active engagement and sustained contribution.
            </li>
          </ul>
          <h3>ii. Blockchain Integration and IMO Tokenization</h3>
          <p>
            The OpenAutoDriving ecosystem integrates blockchain technology to support transparent governance, incentivization, and efficient resource distribution. Key mechanisms include:
          </p>
          <ul>
            <li>
              <strong>IMO Tokenization through ERC-7641</strong>: The governance and incentivization model is built on the ERC-7641 standard, a revenue-sharing token protocol. This enables a transparent mechanism for distributing revenue generated by AutoDriving DAO among contributors and token holders, ensuring fair compensation and engagement across the ecosystem.
            </li>
            <li>
              <strong>On-Chain DAO Governance</strong>: The AutoDriving DAO will leverage a fully on-chain governance structure, allowing token holders to participate in all major decisions. This encompasses governance of the OAD models, resource allocation, and project direction. The decentralization of decision-making ensures that the development process remains open, accessible, and governed by the community.
            </li>
            <li>
              <strong>Model Verifiability with opML</strong>: The integration of Optimistic Machine Learning (opML) technology ensures that the training and inference processes of OAD models are verifiable on-chain. This verifiability enables transparent and trustless rewards for contributors, such as machine learning engineers and GPU providers, who are compensated fairly in tokens based on their contribution of computational resources.
            </li>
          </ul>
          <h3>iii. Ecosystem and Stakeholders</h3>
          <p>
            The success of the AutoDriving DAO ecosystem is contingent on the coordinated participation of various stakeholders, each contributing to and benefiting from the development of the OAD models:
          </p>
          <ol>
            <li>
              <strong>Investors</strong>: Investors play a critical role in the ecosystem by acquiring and holding OAD tokens. Through token ownership, investors gain voting rights in the DAO and stand to benefit from the appreciation of tokens as the platform scales and the models mature.
            </li>
            <li>
              <strong>Original Equipment Manufacturers (OEMs)</strong>: OEMs can leverage OAD models as a foundational technology for their autonomous driving systems. OEMs that contribute data and other resources to the ecosystem enhance the models' performance, fostering a mutually beneficial relationship between the DAO and manufacturers.
            </li>
            <li>
              <strong>Developers and Researchers</strong>: The open-source framework invites contributions from developers, researchers, and academic institutions. Contributors are compensated through token rewards for their work in improving model architecture, algorithm design, and data-driven innovations, fostering a sustainable, incentivized research and development environment.
            </li>
            <li>
              <strong>End-Users and Subscribers</strong>: The OAD models will power various autonomous driving-related applications, which can be accessed by end-users and subscribers. These users can easily utilize OAD’s advanced capabilities by paying for services in OAD tokens, ensuring ongoing demand for the ecosystem's products and services.
            </li>
            <li>
              <strong>Cloud Computing Providers</strong>: Providers of cloud computing resources, essential for the training of large-scale AI models, are integrated into the ecosystem and compensated in OAD tokens. This ensures that adequate computing resources are always available to support the continuous development of OAD models.
            </li>
          </ol>
          <h3>iv. Funding and Resources</h3>
          <p>
            A core challenge of developing state-of-the-art AI models for autonomous driving is securing the necessary funding and computational resources, particularly for the training and refinement of large models. The AutoDriving DAO addresses these challenges through an innovative Initial Model Offering (IMO) strategy:
          </p>
          <ul>
            <li>
              <strong>Computing Resources</strong>: The computational power required for training autonomous driving models is secured through strategic partnerships with cloud computing providers. These providers are compensated in OAD tokens, ensuring continuous access to the necessary resources for model training and inference.
            </li>
            <li>
              <strong>Data Acquisition</strong>: The success of OAD models is directly tied to the quality and quantity of data they are trained on. OEMs and other data contributors are incentivized to share high-quality driving and sensor data in exchange for OAD tokens, ensuring that the models are constantly improving and remain competitive in real-world applications.
            </li>
          </ul>
          <p>
            Through these mechanisms, the AutoDriving DAO ensures a steady flow of resources—both computational and data-based—allowing the OAD models to evolve and improve continuously. This resource-driven approach, combined with decentralized governance, positions the DAO as a leader in the development of open-source autonomous driving technologies.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Data & GPU -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Data & GPU Resources</h2>
        <div class="content has-text-justified">
          <h5>Data Collection and Contribution</h5>
          <p>
            OEMs deploying OAD models in real-world driving scenarios will generate valuable data, including sensor readings and driving patterns. They are incentivized to contribute these data back to the ecosystem for OAD tokens in return, thus creating a positive feedback loop where better data leads to better models and more value for all participants.
          </p>
          <p>
            To further augment data collection, we introduce gamified data labeling through a simulation game where players engage in driving scenarios, labeling data such as obstacles and traffic conditions. Participants earn tokens, turning data labeling into a fun, community-driven effort that improves the model’s training dataset.
          </p>
          <h5>GPU and Computing Resources</h5>
          <p>
            Initially, traditional cloud computing services will be used for AI model training, with payments made in OAD tokens. In addition to external cloud services, we have access to open data centers with 10,000 GPUs, dedicated to supporting OAD models through Initial Model Offering (IMO). This ensures contributors have access to top-tier infrastructure, promoting active development without funding or resource limitations.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Youtube video -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <!-- Paper video. -->
      <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video">
            <!-- Youtube embed code here -->
            <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End youtube video -->




<!-- Paper poster -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>
      <div class="column is-four-fifths">

        <iframe  src="static/pdfs/OAD Whitepaper.pdf" width="100%" height="550">
        </iframe>
      </div>  
    </div>
  </section>
<!--End paper poster -->





  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
